{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 5: Modelo de clasificación de ligandos\n",
    "\n",
    "> **Nota:** Este libro esta disponible de dos maneras: \n",
    "> 1. Descargando el repositorio y siguiendo las instrucciones que estan en el archivo [README.md](https://github.com/ramirezlab/CHEMO/blob/main/README.md)\n",
    "> 2. Haciendo clic aquí en [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ramirezlab/PILE/blob/main/3.%20Machine%20learning%3A%20teor%C3%ADa%20y%20aplicaciones%20en%20el%20dise%C3%B1o%20de%20f%C3%A1rmacos/3.2_Practica-1.es.ipynb?hl=es)\n",
    "\n",
    "## Introducción\n",
    "El aprendizaje automático se ha consolidado como un componente esencial en la ciencia de datos, habilitando a las computadoras para aprender de los datos y tomar decisiones o hacer predicciones sin ser explícitamente programadas para ello. Dentro de este marco, un algoritmo de particular importancia es el modelo de clasificación de *RandomForest*.\n",
    "\n",
    "<img src=\"./img/random_forest_es.png\" width=\"600\" align='right'>\n",
    "\n",
    "El modelo de RandomForest es un algoritmo de aprendizaje supervisado que se fundamenta en el método de ensamble. Este método conjuga varios algoritmos más débiles para conformar un modelo más potente y robusto. En el caso de RandomForest, se crea un \"bosque\" de *árboles de decisión*, cada uno entrenado en un subconjunto aleatorio de los datos <sup> **1** </sup>. El resultado final es la combinación de las predicciones de todos estos árboles individuales.\n",
    "\n",
    "RandomForest se caracteriza por ser versátil y eficiente, capaz de manejar un gran número de características y de abordar tanto problemas de clasificación como de regresión. Una de las ventajas de este algoritmo es que proporciona una medida de la importancia de las variables, ofreciendo un conocimiento valioso acerca del modelo y los datos.\n",
    "\n",
    "### Estrategia de validación: validación cruzada de K-fold\n",
    "\n",
    "La validación de modelos es un paso crucial en el desarrollo de cualquier algoritmo de aprendizaje automático. Su finalidad es evaluar qué tan bien el modelo aprendido puede generalizar a datos no vistos, es decir, que no se utilizaron durante la fase de entrenamiento. En nuestra práctica, emplearemos la estrategia de validación cruzada de K-Fold.\n",
    "\n",
    "<img src=\"./img/K-fold_Cross_Validation_es.png\" width=\"500\" align='left'>\n",
    "\n",
    "La validación cruzada de K-Fold es una técnica potente y ampliamente utilizada que mejora la estimación del rendimiento del modelo. En vez de dividir el conjunto de datos una sola vez en un conjunto de entrenamiento y un conjunto de prueba, la validación cruzada de K-Fold divide el conjunto en 'K' subconjuntos distintos. Luego, el algoritmo se entrena 'K' veces, utilizando en cada ocasión un subconjunto diferente como conjunto de prueba y el resto de los subconjuntos como conjunto de entrenamiento. Finalmente, el rendimiento del modelo se promedia en las 'K' iteraciones para obtener una estimación más robusta <sup> **2** </sup>.\n",
    "\n",
    "El objetivo es probar la capacidad del modelo para predecir datos no vistos anteriormente, detectar problemas como el sobreajuste y evaluar la capacidad de generalización del modelo.\n",
    "\n",
    "\n",
    "### Medidas de desempeño\n",
    "\n",
    "La elección de las medidas de desempeño depende de la naturaleza del problema que se está abordando. Sin embargo, hay algunas medidas comunes que suelen ser útiles para evaluar el rendimiento de los modelos de clasificación. Para entender y calcular estas medidas de desempeño, es útil conocer sus fórmulas. Antes de proporcionar las fórmulas, es importante destacar que se basan en los conceptos de Verdaderos Positivos (**TP**), Falsos Positivos (**FP**), Verdaderos Negativos (**TN**), y Falsos Negativos (**FN**), que son las cuatro categorías posibles en las que se pueden clasificar las predicciones de nuestro modelo. La matriz de confusión resulta útil para diferenciar cada concepto <sup> **3** </sup>:\n",
    "\n",
    "<img src=\"./img/confusion_matrix_es.png\" width=\"400\">\n",
    "\n",
    "* **Exactitud (Accuracy)**: Es la proporción de predicciones correctas entre el total de predicciones realizadas. Aunque es una medida intuitiva y fácil de entender, la exactitud puede ser engañosa si las clases están desequilibradas. La exactitud se calcula como la suma de las predicciones correctas (tanto positivas como negativas) dividida por el total de predicciones.\n",
    "  $$Accuracy = \\dfrac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "* **Precisión (Precision)**: Es la proporción de predicciones positivas que fueron correctas. Es una medida útil cuando los falsos positivos son particularmente preocupantes. La precisión se calcula como el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos positivos.\n",
    "  $$Precision = \\dfrac{TP}{TP+FP}$$\n",
    "\n",
    "* **Recall (Sensibilidad)**: Es la proporción de casos positivos reales que el modelo identificó correctamente. Es importante cuando los falsos negativos son una preocupación. El recall se calcula como el número de verdaderos positivos dividido por la suma de verdaderos positivos y falsos negativos.\n",
    "  $$Recall = \\dfrac{TP}{TP + FN}$$\n",
    "\n",
    "* **Puntuación F1 (F1 Score)**: Es la media armónica de la precisión y el recall. Esta medida busca un equilibrio entre la precisión y el recall. La puntuación F1 se calcula como el promedio armónico de la precisión y el recall.\n",
    "  $$F1_{score} = 2 \\times \\dfrac{Precision \\times Recall}{Precision + Recall}$$\n",
    "\n",
    "* **Curva ROC (Receiver Operating Characteristic)** <sup> **3** </sup>: Esta curva es una representación gráfica que ilustra la capacidad discriminativa de un clasificador binario a medida que varía su umbral de discriminación. Se crea trazando la tasa de verdaderos positivos (Recall) contra la tasa de falsos positivos (1-Especificidad), a varios niveles de umbral. Un modelo con un poder predictivo perfecto se ubicaría en la esquina superior izquierda del gráfico, mientras que un modelo aleatorio seguiría la línea diagonal.\n",
    "\n",
    "* **AUC (Área bajo la curva, en inglés Area Under the Curve)**: Esta métrica se calcula como el área bajo la curva ROC. Un AUC de 1.0 denota un modelo perfecto, mientras que un AUC de 0.5 denota un modelo que no tiene capacidad de discriminación, equivalente a una selección aleatoria. Cuanto mayor sea el AUC, mejor será el modelo en distinguir entre las clases positiva y negativa.\n",
    "\n",
    "En nuestro análisis de la implementación del modelo RandomForest, utilizaremos estas medidas para evaluar su desempeño y capacidad de generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de los datos\n",
    "Iniciamos importando los datos de la práctica anterior, como estos están guardados en la carpeta de la segunda parte, podemos crear un `directorio raíz` (`ROOT_DIR`) para navegar hasta el archivo y cargarlo en un dataframe\n",
    "\n",
    "## Carga de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:43.420878700Z",
     "start_time": "2023-09-29T00:17:42.577993300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se importa la librería Pandas con el alias 'pd'\n",
    "import pandas as pd\n",
    "\n",
    "# Se importa el módulo 'os' para operaciones con el sistema de archivos\n",
    "import os\n",
    "\n",
    "# Se importa 'Path' desde la librería 'pathlib' para trabajar con rutas de archivos de forma más flexible\n",
    "from pathlib import Path\n",
    "\n",
    "# Se importa la librería 'requests' para realizar solicitudes HTTP\n",
    "import requests\n",
    "\n",
    "# Definir el ID de UniProt y la URL del archivo CSV\n",
    "uniprot_id = 'P49841'\n",
    "csv_url = 'https://raw.githubusercontent.com/ramirezlab/PILE/refs/heads/main/2.%20De%20datos%20a%20gr%C3%A1ficas%3A%20Propiedades%20drug-likeness%20y%20similitud%20qu%C3%ADmica%20con%20python/data/compounds_P49841_lipinski.csv'\n",
    "\n",
    "# Leer el archivo CSV desde la URL y cargarlo en un DataFrame\n",
    "df_output = pd.read_csv(csv_url)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "df_output.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica necesitamos solamente los ligandos que cumplen la *regla de los cinco*, por tanto, debemos filtrar por la columna: `rule_of_five_conform:yes`. Además, solamente necesitamos las primeras tres columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:43.420878700Z",
     "start_time": "2023-09-29T00:17:42.857454700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imprime el número total de ligandos en el DataFrame original\n",
    "print(f'# lignados totales: {len(df_output)}')\n",
    "\n",
    "# Filtra el DataFrame para conservar solo los ligandos que cumplen con la regla de Lipinski (rule_of_five_conform == 'yes')\n",
    "df_output = df_output[df_output['rule_of_five_conform']=='yes']\n",
    "\n",
    "# Selecciona solo las columnas relevantes: ID del ligando, valor pChEMBL y cadena SMILES\n",
    "df_output = df_output[['molecule_chembl_id', 'pchembl_value', 'smiles']]\n",
    "\n",
    "# Imprime el número de ligandos que cumplen con la regla de Lipinski\n",
    "print(f'# ligandos filtrados (rule_of_five_conform:yes): {len(df_output)}')\n",
    "\n",
    "# Muestra las primeras filas del DataFrame filtrado\n",
    "df_output.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Procesamiento de los datos\n",
    "### Huellas Dactilares Moleculares (Fingerprints)\n",
    "\n",
    "Para entrenar nuestro algoritmo, es necesario convertir los ligandos en una lista de características. Actualmente, disponemos de la estructura molecular (SMILES) de cada ligando, y con esta información podemos generar una representación alternativa conocida como *fingerprint*. Esta representación se utilizará posteriormente para entrenar el modelo.\n",
    "\n",
    "Para identificar y generar las huellas dactilares de cada ligando, utilizaremos la librería `rdkit`. Esta operación resultará en la creación de una nueva columna en nuestro conjunto de datos que contendrá el fingerprint de cada ligando. Existen varios tipos de fingerprints, pero en esta ocasión trabajaremos con la [Extended Connectivity Fingerprint ECFP](https://docs.chemaxon.com/display/docs/extended-connectivity-fingerprint-ecfp.md) también conocida como morgan2_c/ecfp4 <sup> **4** </sup>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:45.543165100Z",
     "start_time": "2023-09-29T00:17:42.874935800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se instala la librería RDKit (si no está previamente instalada)\n",
    "!pip install rdkit\n",
    "\n",
    "# Se importa el módulo 'Chem' desde RDKit para manipular moléculas\n",
    "from rdkit import Chem\n",
    "\n",
    "# Se importa el módulo 'rdMolDescriptors' desde RDKit para generar descriptores moleculares\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "# Se crea una copia del DataFrame original para trabajar con los fingerprints\n",
    "df_fp = df_output.copy()\n",
    "\n",
    "# Se calcula el fingerprint de Morgan (radio 2) para cada molécula a partir de su cadena SMILES\n",
    "# 'Chem.MolFromSmiles(smile)' convierte la cadena SMILES en un objeto Mol\n",
    "# 'GetMorganFingerprintAsBitVect(..., 2)' genera el fingerprint como vector binario\n",
    "# 'ToList()' convierte el fingerprint a una lista de enteros (0s y 1s)\n",
    "df_fp['morgan2_c'] = df_output.smiles.map(lambda smile: rdMolDescriptors.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smile), 2).ToList())\n",
    "\n",
    "# Se seleccionan solo las columnas relevantes: ID del ligando, fingerprint de Morgan y valor pChEMBL\n",
    "df_fp = df_fp[['molecule_chembl_id', 'morgan2_c', 'pchembl_value']]\n",
    "\n",
    "# Se muestran las primeras filas del DataFrame con los fingerprints\n",
    "df_fp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploremos el primer fingerprint: una lista binaria (unos y ceros) con una longitud de 2048 elementos. Estos elementos de la fingerprint serán las características que se usarán para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:45.546957500Z",
     "start_time": "2023-09-29T00:17:45.532546200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imprime el fingerprint de Morgan (como lista de 0s y 1s) correspondiente al primer ligando del DataFrame\n",
    "print(df_fp.morgan2_c[0])\n",
    "\n",
    "# Imprime la longitud del fingerprint del primer ligando (número total de bits en el vector)\n",
    "print(len(df_fp.morgan2_c[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación de los ligandos\n",
    "\n",
    "Cada ligando debe ser clasificado como **activo** o **inactivo**, para esto usaremos la columna `pchembl_value` definiendo umbrales de actividiad\n",
    "La proteína *Glycogen synthase kinase-3 beta* se clasifica en el grupo de las *Kinasas*, por tanto, usaremos los siguientes umbrales:\n",
    "\n",
    "**Inactivo**: *pchembl_value* < 6.52 uM\n",
    "\n",
    "**Activo**: *pchembl_value* >= 7.52 uM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:45.606071300Z",
     "start_time": "2023-09-29T00:17:45.546957500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Añadir una nueva columna llamada 'activity_type', con valor por defecto 'Intermediate'\n",
    "df_fp['activity_type'] = 'Intermediate'\n",
    "\n",
    "# Marcar como 'Active' aquellas moléculas con un valor de pChEMBL mayor o igual a 7.5\n",
    "df_fp.loc[df_fp[df_fp.pchembl_value >= 7.5].index, 'activity_type'] = 'Active'\n",
    "\n",
    "# Marcar como 'Inactive' aquellas moléculas con un valor de pChEMBL menor a 6.52\n",
    "df_fp.loc[df_fp[df_fp.pchembl_value < 6.52].index, 'activity_type'] = 'Inactive'\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame actualizado\n",
    "df_fp.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos gráficamente cómo quedo la clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:20:01.072935200Z",
     "start_time": "2023-09-29T00:20:00.962976200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imprime la cantidad de moléculas clasificadas en cada categoría de actividad (Active, Intermediate, Inactive)\n",
    "print(df_fp.activity_type.value_counts())\n",
    "\n",
    "# Genera un gráfico de barras que muestra la distribución de moléculas por tipo de actividad\n",
    "df_fp.activity_type.value_counts().plot.bar(x='activity_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora filtramos los datos quitando aquellos que se calsificaron como *Intermedios*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:20:03.206796900Z",
     "start_time": "2023-09-29T00:20:03.067809700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se crea un nuevo DataFrame 'bd' que contiene solo las moléculas clasificadas como 'Active' o 'Inactive'\n",
    "# Se excluyen las de tipo 'Intermediate' y se hace una copia del subconjunto\n",
    "bd = df_fp[df_fp['activity_type'] != 'Intermediate'].copy()\n",
    "\n",
    "# Se genera un gráfico de barras que muestra la cantidad de ligandos activos e inactivos\n",
    "bd.activity_type.value_counts().plot.bar(x='activity_type')\n",
    "\n",
    "# Se imprime el número total de ligandos en el nuevo DataFrame (solo activos e inactivos)\n",
    "print(f'# ligandos (active/inactive): {len(bd)}')\n",
    "\n",
    "# Se imprime el conteo de ligandos por categoría de actividad (Active, Inactive)\n",
    "print(bd.activity_type.value_counts())\n",
    "\n",
    "# Se muestran las primeras filas del DataFrame 'bd'\n",
    "bd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es una clasificación binaria, debemos asignar una etiqueta: (Inactive:0 / Active:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:45.978080900Z",
     "start_time": "2023-09-29T00:17:45.828076Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se añade una nueva columna llamada 'activity' y se inicializa con el valor 0 (por defecto todas las moléculas son inactivas)\n",
    "bd['activity'] = 0\n",
    "\n",
    "# Se asigna el valor 1.0 en la columna 'activity' a las moléculas clasificadas como 'Active'\n",
    "bd.loc[bd[bd.activity_type == 'Active'].index, 'activity'] = 1.0\n",
    "\n",
    "# Se eliminan las columnas 'activity_type' y 'pchembl_value' del DataFrame, ya que no se usarán en el modelo\n",
    "bd.drop(['activity_type', 'pchembl_value'], axis=1, inplace=True)\n",
    "\n",
    "# Se muestran las primeras filas del DataFrame actualizado\n",
    "bd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos las características (morgan2_c fingerprint) y etiquetas (activity) para poder entrenar el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Entrenamiento del modelo con el algoritmo *Random Forest*\n",
    "\n",
    "Vamos a entrenar un modelo de Random Forest que clasifique ligandos conociendo el fingerprint. El objetivo es probar la capacidad del modelo para predecir datos que nunca antes había visto para detectar problemas conocidos como sobreajuste y evaluar la capacidad de generalización del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Usualmente, el primer paso es **dividir** el conjunto de datos, una parte para el entrenamiento (70%) y la otra parte para la prueba(30%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:46.021961Z",
     "start_time": "2023-09-29T00:17:45.844671200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se importa la función 'train_test_split' del módulo 'model_selection' de scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Se divide el DataFrame 'bd' en conjuntos de entrenamiento y prueba\n",
    "# 'test_size=0.3' indica que el 30% de los datos se utilizarán para prueba\n",
    "# 'random_state=142857' garantiza la reproducibilidad de la partición\n",
    "# 'shuffle=True' mezcla aleatoriamente los datos antes de dividirlos\n",
    "# 'stratify=bd['activity']' asegura que la proporción de clases (0 e 1) se mantenga en ambos conjuntos\n",
    "fp_df_train, fp_df_test = train_test_split(bd, test_size=0.3, random_state=142857,\n",
    "                                            shuffle=True, stratify=bd['activity'])\n",
    "\n",
    "# Se reinicia el índice de los DataFrames de entrenamiento y prueba para evitar duplicados o índices desordenados\n",
    "fp_df_train.reset_index(drop=True, inplace=True)\n",
    "fp_df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Se imprime la cantidad de datos en los conjuntos de entrenamiento y prueba\n",
    "print(f'# datos entrenamiento: {len(fp_df_train)},'\n",
    "      f'\\n# datos prueba: {len(fp_df_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para cada conjunto vamos a separar las características (el fingerprint) y la etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:46.021961Z",
     "start_time": "2023-09-29T00:17:45.859254300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se separan las variables de entrada (X) y la variable objetivo (y) para el conjunto de entrenamiento\n",
    "X_train, y_train = fp_df_train.morgan2_c, fp_df_train.activity\n",
    "\n",
    "# Se separan las variables de entrada (X) y la variable objetivo (y) para el conjunto de prueba\n",
    "X_test, y_test = fp_df_test.morgan2_c, fp_df_test.activity\n",
    "\n",
    "# Los vectores de características se convierten en listas de elementos para su uso en modelos de scikit-learn\n",
    "X_train, X_test = X_train.tolist(), X_test.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escogemos el estimador de [Random Fores classificator](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) para entrenar el modelo, se debe instanciar y construir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:46.686556300Z",
     "start_time": "2023-09-29T00:17:45.873284100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se importa la clase 'RandomForestClassifier' desde el módulo 'ensemble' de scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Se crea una instancia del modelo de clasificación Random Forest\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación\n",
    "### Accuracy score\n",
    "\n",
    "Existen varias métricas para medir la capacidad del modelo para hacer predicciones, vamos a ver un ejemplo usando la métrica [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy_score#sklearn.metrics.accuracy_score).\n",
    "\n",
    "Lo primero es clasificar (*predecir*) los datos del conjunto y luego compararlos con las etiquetas verdaderas, esto lo haremos tanto con el **conjunto de entrenamiento** como con el **conjunto de prueba**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:46.891919800Z",
     "start_time": "2023-09-29T00:17:46.683609600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se importa la función 'accuracy_score' del módulo 'metrics' de scikit-learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Se realiza la predicción del modelo sobre el conjunto de entrenamiento\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Se realiza la predicción del modelo sobre el conjunto de prueba (validación)\n",
    "y_test_pre = model.predict(X_test)\n",
    "\n",
    "# Se calcula la precisión (accuracy) para el conjunto de entrenamiento\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Se calcula la precisión (accuracy) para el conjunto de prueba\n",
    "acc_test = accuracy_score(y_test, y_test_pre)\n",
    "\n",
    "# Se imprimen las puntuaciones de precisión con 4 decimales y en formato porcentual\n",
    "print(f'Accuracy conjunto de entrenamiento: {acc_train:.4f} ({acc_train:.2%})\\n'\n",
    "      f'Accuracy conjunto de prueba: {acc_test:.4f} ({acc_test:.2%})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El *accuracy* del conjunto de entrenamiento es del 100%, lo cual indica un caso de Sobreajuste (*Overfitting*), posiblemente se deba hacer un ajuste de los parámetros del modelo de clasificación o incluso utilizar otro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión\n",
    "Con esta matriz se puede comparar las etiquetas verdaderas versus las predicciones del modelo, [aquí](https://en.wikipedia.org/wiki/Confusion_matrix) se puede ver más información sobre la matriz de confusión. En este caso vamos a comparar los datos del conjunto de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:47.005077600Z",
     "start_time": "2023-09-29T00:17:46.887931400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se importa la clase 'ConfusionMatrixDisplay' del módulo 'metrics' de scikit-learn para visualizar matrices de confusión\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Se importa la librería Matplotlib para visualización\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Se genera y muestra la matriz de confusión a partir de las predicciones del conjunto de prueba\n",
    "# 'colorbar=False' desactiva la barra de colores\n",
    "# 'cmap=plt.cm.Blues' establece una paleta de color azul para la visualización\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pre, colorbar=False,  cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede trabajar con los datos normalizados para verlos en forma de porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:47.086988100Z",
     "start_time": "2023-09-29T00:17:46.980928800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Se genera y muestra la matriz de confusión normalizada a partir de las predicciones del conjunto de prueba\n",
    "# 'colorbar=False' desactiva la barra de colores\n",
    "# 'cmap=plt.cm.Blues' establece una paleta de colores en tonos azules\n",
    "# 'normalize=\"true\"' normaliza la matriz por fila, mostrando proporciones en lugar de conteos absolutos\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pre, colorbar=False,\n",
    "                                        cmap=plt.cm.Blues, normalize='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC\n",
    "La curva ROC (ROC curve, Receiver Operating Characteristic) es una representación gráfica de la sensibilidad frente a la especificidad para un sistema clasificador binario según se varía el umbral de discriminación, usualmente se suele utilizar para representar qué tan bueno es el modelo, veamos como se puede construir una:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:47.486882900Z",
     "start_time": "2023-09-29T00:17:47.073394900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se importan las funciones 'roc_curve' y 'auc' del módulo 'metrics' de scikit-learn para evaluar el rendimiento del modelo\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Se importan las librerías de Matplotlib para visualización\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Se obtienen las probabilidades predichas para la clase positiva (1) en el conjunto de entrenamiento\n",
    "pred_prob_train = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Se obtienen las probabilidades predichas para la clase positiva (1) en el conjunto de prueba\n",
    "pred_prob_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Se calculan las tasas de falsos positivos (FPR) y verdaderos positivos (TPR) para el conjunto de entrenamiento\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, pred_prob_train)\n",
    "# Se calcula el área bajo la curva (AUC) para el conjunto de entrenamiento\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "# Se calculan las tasas de falsos positivos (FPR) y verdaderos positivos (TPR) para el conjunto de prueba\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, pred_prob_test)\n",
    "# Se calcula el área bajo la curva (AUC) para el conjunto de prueba\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Se crea una figura para graficar las curvas ROC\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "# Se grafica la curva ROC para el conjunto de entrenamiento\n",
    "plt.plot(fpr_train, tpr_train, label=f'AUC train = {roc_auc_train:.2f}', lw=2)\n",
    "\n",
    "# Se grafica la curva ROC para el conjunto de prueba\n",
    "plt.plot(fpr_test, tpr_test, label=f'AUC test = {roc_auc_test:.2f}', lw=2)\n",
    "\n",
    "# Se grafica una línea diagonal como referencia de un clasificador aleatorio\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random', lw=2, color=\"black\")  # Curva aleatoria\n",
    "\n",
    "# Se configuran etiquetas y título del gráfico\n",
    "plt.xlabel('False positive rate', size=24)\n",
    "plt.ylabel('True positive rate', size=24)\n",
    "plt.title('Random forest ROC curves', size=24)\n",
    "\n",
    "# Se ajusta el tamaño de las etiquetas de los ejes\n",
    "plt.tick_params(labelsize=16)\n",
    "\n",
    "# Se muestra la leyenda del gráfico\n",
    "plt.legend(fontsize=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold (validación cruzada)\n",
    "\n",
    "Vamos dividir los datos en 5 conjuntos, cada uno de ellos entrenará el algoritmo y medirá su capacidad de predicción, luego se contrastarán los datos de los cinco modelos para validar si el modelo entrenado funciona o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:51.665009400Z",
     "start_time": "2023-09-29T00:17:47.483357600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "n_folds = 5\n",
    "# Vector vacío para almacenar resultados\n",
    "results = []\n",
    "\n",
    "# Mezcla los índices para validación cruzada con k-fold\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "# Etiquetas inicializadas en -1 para cada punto de datos\n",
    "labels = -1 * np.ones(len(bd))\n",
    "\n",
    "# Instancia del modelo\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "for train_index, test_index in kf.split(bd):\n",
    "    # Entrenamiento\n",
    "    # Convierte los vectores binarios y etiquetas en listas\n",
    "    train_x = bd.iloc[train_index].morgan2_c.tolist()\n",
    "    train_y = bd.iloc[train_index].activity.tolist()\n",
    "\n",
    "    # Ajustar el modelo con los datos de entrenamiento\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    # Prueba\n",
    "    # Convierte los vectores binarios y etiquetas en listas\n",
    "    test_x = bd.iloc[test_index].morgan2_c.tolist()\n",
    "    test_y = bd.iloc[test_index].activity.tolist()\n",
    "\n",
    "    # Predecir probabilidades en el conjunto de prueba\n",
    "    prediction_prob = model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "    # Guardar la etiqueta predicha para cada pliegue\n",
    "    labels[test_index] = model.predict(test_x)\n",
    "\n",
    "    # Evaluación\n",
    "    # Obtener FPR, TPR y AUC para cada pliegue\n",
    "    fpr_l, tpr_l, _ = roc_curve(test_y, prediction_prob)\n",
    "    roc_auc_l = auc(fpr_l, tpr_l)\n",
    "\n",
    "    # Agregar los resultados del pliegue\n",
    "    results.append((fpr_l, tpr_l, roc_auc_l))\n",
    "\n",
    "# Calcular métricas generales: precisión, sensibilidad y especificidad\n",
    "y = bd.activity.tolist()\n",
    "acc = accuracy_score(y, labels)\n",
    "sens = recall_score(y, labels)\n",
    "spec = (acc * len(y) - sens * sum(y)) / (len(y) - sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:52.088460Z",
     "start_time": "2023-09-29T00:17:51.669390400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se crea una figura para graficar con tamaño de 7x7 pulgadas\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "# Se obtiene un mapa de color azul desde Matplotlib\n",
    "cmap = mpl.colormaps['Blues']\n",
    "\n",
    "# Se genera una lista de colores a partir del mapa de color, espaciados uniformemente según el número de pliegues\n",
    "colors = [cmap(i) for i in np.linspace(0.1, 1.0, n_folds)]\n",
    "\n",
    "# Se recorre la lista de resultados obtenidos de la validación cruzada\n",
    "for i, (fpr_l, tpr_l, roc_auc_l) in enumerate(results):\n",
    "    # Se grafica la curva ROC de cada pliegue con su respectivo AUC\n",
    "    plt.plot(fpr_l, tpr_l, label='AUC CV$_{0}$ = {1:0.2f}'.format(str(i), roc_auc_l), lw=2, color=colors[i])\n",
    "    # Se definen los límites del eje x\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    # Se definen los límites del eje y\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "\n",
    "# Se grafica una línea diagonal que representa un clasificador aleatorio\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random', lw=2, color=\"black\")  # Curva aleatoria\n",
    "\n",
    "# Se establece la etiqueta del eje x\n",
    "plt.xlabel('False positive rate', size=24)\n",
    "\n",
    "# Se establece la etiqueta del eje y\n",
    "plt.ylabel('True positive rate', size=24)\n",
    "\n",
    "# Se establece el título del gráfico\n",
    "plt.title(f'Random forest ROC curves', size=24)\n",
    "\n",
    "# Se ajusta el tamaño de las etiquetas de los ejes\n",
    "plt.tick_params(labelsize=16)\n",
    "\n",
    "# Se muestra la leyenda del gráfico\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "# Se muestra el gráfico en pantalla\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-29T00:17:52.110725300Z",
     "start_time": "2023-09-29T00:17:52.087463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calcular el AUC medio a partir de los resultados de los pliegues e imprimirlo\n",
    "m_auc = np.mean([elem[2] for elem in results])\n",
    "print(f'Mean AUC: {m_auc:.3f}')\n",
    "\n",
    "# Mostrar en pantalla las métricas generales: sensibilidad, precisión y especificidad\n",
    "print(f'Sensitivity: {sens:.3f}\\nAccuracy: {acc:.3f}\\nSpecificity: {spec:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Conclusiones\n",
    "El algoritmo de clasificación Random Forest es excepcionalmente potente para realizar clasificaciones binarias. En el caso de nuestro estudio, esto implicó clasificar moléculas como activas o inactivas. No obstante, nuestra implementación inicial del modelo reveló un sobreajuste significativo de los datos. Este fenómeno sugiere que el algoritmo intenta captar todas las características de las moléculas en lugar de lograr una generalización efectiva. Un exceso de ajuste puede llevar a una baja capacidad de predicción para moléculas que no forman parte del conjunto de entrenamiento, un escenario que preferiríamos evitar.\n",
    "\n",
    "## Actividad práctica\n",
    "\n",
    "Para reducir el problema de sobreajuste, puedes modificar los [parámetros del modelo](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier), los cuales regulan cómo se lleva a cabo el entrenamiento. \n",
    "\n",
    "Como actividad práctica, se te invita a experimentar con la modificación de estos parámetros y comparar los resultados obtenidos. ¿Puedes encontrar un conjunto de parámetros que reduzca el sobreajuste y mejore el rendimiento general del modelo? ¿Cómo afectan estos cambios a las diferentes métricas de desempeño? Explora y comparte tus hallazgos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "1. Sarica, A., Cerasa, A., & Quattrone, A. (2017). Random forest algorithm for the classification of neuroimaging data in alzheimer’s disease: A systematic review. Frontiers in Aging Neuroscience, 9. https://www.frontiersin.org/articles/10.3389/fnagi.2017.00329\n",
    "2. Refaeilzadeh, P., Tang, L., & Liu, H. (2009). Cross-validation. En L. LIU & M. T. ÖZSU (Eds.), Encyclopedia of Database Systems (pp. 532-538). Springer US. https://doi.org/10.1007/978-0-387-39940-9_565\n",
    "3. Larrañaga, P., Calvo, B., Santana, R., Bielza, C., Galdiano, J., Inza, I., Lozano, J. A., Armañanzas, R., Santafé, G., Pérez, A., & Robles, V. (2006). Machine learning in bioinformatics. Briefings in Bioinformatics, 7(1), 86-112. https://doi.org/10.1093/bib/bbk007\n",
    "4. Extended connectivity fingerprint ecfp | chemaxon docs. (s. f.). https://docs.chemaxon.com/display/docs/extended-connectivity-fingerprint-ecfp.md\n",
    "5. Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 785–794). New York, NY, USA: ACM. https://doi.org/10.1145/2939672.2939785"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
