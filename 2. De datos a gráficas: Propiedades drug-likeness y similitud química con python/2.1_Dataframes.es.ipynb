{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4697f74c",
   "metadata": {},
   "source": [
    "# Introducción a la manipulación de Estructuras de Datos avanzadas con Pandas\n",
    "\n",
    "> **Nota:** Este libro esta disponible de dos maneras\n",
    "> 1. Descargando el repositorio y siguiendo las instrucciones que estan en el archivo [README.md](https://github.com/ramirezlab/CHEMO/blob/main/README.md)\n",
    "> 2. Haciendo clic aquí en [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ramirezlab/CHEMO/blob/main/2_PART_TWO/2.1_Dataframes.es.ipynb)\n",
    "\n",
    "\n",
    "## Librería Numpy\n",
    "\n",
    "*Numpy* es una librería de Python fundamental para la computación científica. Entre sus características está la creación de arreglos multidimensionales, que se pueden tratar como vectores, y posee una gran rapidez a la hora de hacer operaciones matemáticas sobre los mismos. Lo cual la hace una herramienta necesaria para proyectos con requerimientos de alta computación y cálculo matemático y es por eso de su gran popularidad en el ecosistema científico.\n",
    "\n",
    "### Operaciones matemáticas con Arreglos de Numpy\n",
    "\n",
    "Para empezar, importaremos la librería y creamos nuestro primer Arreglo de Numpy, luego lo afectaremos con algunas operaciones matemáticas básicas. Es común renombrar la librería `Numpy` como `np`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82d819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.357654Z",
     "start_time": "2023-04-11T16:50:30.429326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se importa la librería numpy. Por lo general el acrónimo para la librería numpy es np.\n",
    "import numpy as np\n",
    "\n",
    "# Se crea un arreglo de números\n",
    "nums = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Se imprime el valor del arreglo\n",
    "nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4e2c7",
   "metadata": {},
   "source": [
    "**Vale la pena mencionar que un arreglo de Numpy se parece mucho a una lista nativa de Python.** La diferencia principal radica en el tipo de operaciones de orden matemático que se pueden realizar sobre un arreglo de la librería y las listas nativas de Python.\n",
    "\n",
    "Tomemos como punto de partida la suma de dos arreglos de `Numpy`, comparado con una suma de listas de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b4c21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.357654Z",
     "start_time": "2023-04-11T16:50:30.526583Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se imprime la suma del arreglo de Numpy\n",
    "nums + nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60595dbe",
   "metadata": {},
   "source": [
    "Se mantuvo el tamaño de la lista, pero sus elementos fueron sumados, y es aquí el potencial y la simpleza de los arreglos de `Numpy`, y el porque de su basto uso en el mundo científico.\n",
    "\n",
    "Miremos un código equivalente con una lista nativa de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f70d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.357654Z",
     "start_time": "2023-04-11T16:50:30.543538Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lista por compresión con adición de sus elementos\n",
    "lista_nums = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "[x + x for x in lista_nums]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124e3af",
   "metadata": {},
   "source": [
    "No creemos que sea complicado estar creando *listas de comprensión* de Python, pero claramente se reducirían las líneas de código en nuestro programa usando los arreglos de **Numpy**. Y sería imposible lograrlo si necesitamos sumar dos listas.\n",
    "\n",
    "Los *arreglos de Numpy* también pueden realizar las demás operaciones siguiendo el mismo modelo:\n",
    "\n",
    "```markdown\n",
    "<arreglo_numpy> <operacion (+, -, *, /)> <arreglo_numpy>\n",
    "```\n",
    "*Tengamos cuidado con la división si hay ceros en el denominador, recordemos que no es posible dividir entre cero, en tal caso saldría un error*\n",
    "\n",
    "Ahora, para ver el potencial de los arreglos de Numpy, ¿qué pasaría si intentamos sumar dos arreglos de tamaño $n$, hablemos de arreglos de $10000000$ elementos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d8fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.359650Z",
     "start_time": "2023-04-11T16:50:30.559495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Se importa la libreria de Numpy\n",
    "import numpy as np\n",
    "\n",
    "#Se crean dos arreglos con 1 millón de elementos, en donde cada elemento tiene un valor aleatorio entre 0-10\n",
    "x = np.random.choice(10, 10000000)\n",
    "y = np.random.choice(10, 10000000)\n",
    "\n",
    "print(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaac0abd",
   "metadata": {},
   "source": [
    "¿Lo vieron? La multiplicación tomo tan solo milisegundos. Y es ahí donde usar la librería vale la pena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e3ca6",
   "metadata": {},
   "source": [
    "##  Introducción a las Series de Pandas\n",
    "\n",
    "Antes de hablar de Dataframes es importante que hagamos un pequeño repaso sobre las **Series**, al mismo tiempo empezaremos a interactuar con la librería de Pandas.\n",
    "\n",
    "**`Pandas`** es una librería de Python (Al igual que `Numpy`), que se caracteriza por proveer estructuras de datos que son de rápido procesamiento, que son fáciles de expresar para hacer que el trabajo con datos relacionales sea muy fácil e intuitivo. [Mas info aqui](https://pandas.pydata.org/docs/getting_started/overview.html)\n",
    "\n",
    "¿Qué es una Serie? ¿Cómo se crea una Serie? Veamos las respuestas a estas preguntas:\n",
    "\n",
    "Las Series son un tipo de estructura unidimensional *(1D)* muy parecida a un arreglo, con la característica de que podemos etiquetar en cierta medida sus datos a través de índices.\n",
    "\n",
    "Para estudiar el potencial de las series vamos a interactuar con el archivo `iris.data` (./data/iris.data) que proviene del repositorio de datos de la [UCI Machine Learning](https://archive-beta.ics.uci.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ebe0f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.359650Z",
     "start_time": "2023-04-11T16:50:30.779018Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# URL para el archivo iris.data\n",
    "url = \"https://raw.githubusercontent.com/ramirezlab/CHEMO/main/2_PART_TWO/data/iris.data\"\n",
    "\n",
    "# Obtener los datos de la URL\n",
    "response = requests.get(url)\n",
    "iris_data = response.text\n",
    "\n",
    "# Crear un DataFrame de los datos obtenidos\n",
    "serie_de_iris = pd.read_csv(StringIO(iris_data), header=None, names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"])\n",
    "\n",
    "# Imprimir el DataFrame\n",
    "print(serie_de_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe775c9",
   "metadata": {},
   "source": [
    "*De ahora en adelante siempre que queramos visualizar el contenido de una serie y/o un Dataframe usaremos el método `head`, el cual solo muestra los primeros datos y no todo el conjunto.*\n",
    "\n",
    "Y así de fácil se construye una estructura de datos básica pero potente que nos da la libreria de *Pandas*. Exploremos lo que tenemos:\n",
    "\n",
    "- Cada renglón es un arreglo de una dimensión con cinco elementos, se imprimieron $150$ filas, cada una con una lista de 5 elementos, más la columna de enumeración.\n",
    "\n",
    "- Las *series* al igual que las listas y arreglos de *Numpy* poseen métodos y su manipulación también se logra por medio de indexación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d36d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.359650Z",
     "start_time": "2023-04-11T16:50:31.046900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ejemplo 1: Se imprime los primeros datos de la serie utilizando el método head.\n",
    "serie_de_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e3909",
   "metadata": {},
   "source": [
    "Otro método útil es el método `index`, devuelve la lista de índices y su rango."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314a01e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.359650Z",
     "start_time": "2023-04-11T16:50:31.062857Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se imprimen los indexes del arreglo, en este caso hace referencia a la primera columna\n",
    "serie_de_iris.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804edc42",
   "metadata": {},
   "source": [
    "Que tal si quisieramos acceder a los elementos de la posicion $120$ en adelante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d588ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.360647Z",
     "start_time": "2023-04-11T16:50:31.078814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se imprimen los elementos desde la posición 120 en adelante\n",
    "serie_de_iris[120:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143e447",
   "metadata": {},
   "source": [
    "Como una *Serie* es una arreglo de una dimensión *(1D)*, cada fila contiene toda la información devuelta por el dataset original, representada en un arreglo nativo de *Python* para su manipulación. **Técnicamente esto hace que sea difícil** la manipulación de los datos al interior de cada serie (por ejemplo, hallar la media de la primera columna, lo que conlleva a que desperdiciemos las funcionalidades nativas de una Serie, porque tendríamos que crear una serie por cada columna de datos, luego serie ineficiente.\n",
    "\n",
    "Veamos un ejemplo de cómo extraer los valores de la primera columna en cuestión, para esto, comenzamos cargando nuevamente el dataset original pero esta vez solo tomamos la primera columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af5138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.360647Z",
     "start_time": "2023-04-11T16:50:31.094789Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# URL para el archivo iris.data\n",
    "url = \"https://raw.githubusercontent.com/ramirezlab/CHEMO/main/2_PART_TWO/data/iris.data\"\n",
    "\n",
    "# Obtener los datos de la URL\n",
    "response = requests.get(url)\n",
    "iris_data = response.text\n",
    "\n",
    "# Se limpia el dataset y se construye la serie a partir del arreglo generado por el `split`\n",
    "iris_dataset = iris_data.split('\\n')\n",
    "\n",
    "# Se extrae del dataset la primera columna y se convierte sus datos a tipo float\n",
    "iris_dataset = [float(j[0]) if j[0] != '' else 0 for j in [i.split(',') for i in iris_dataset]]\n",
    "\n",
    "# Se crea la serie con los datos del dataset\n",
    "serie_de_iris_col_1 = pd.Series(iris_dataset)\n",
    "\n",
    "# Se imprime la serie con la primera columna del dataset\n",
    "print(serie_de_iris_col_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce77d826",
   "metadata": {},
   "source": [
    "Y ahora si podemos encontrar algunas estadísticas como la media de todos los valores, y usaremos *Numpy* para esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546f85f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.360647Z",
     "start_time": "2023-04-11T16:50:31.110274Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Se calcula la media de la serie a partir del metodo mean de numpy\n",
    "print('Tamaño promedio los datos:')\n",
    "np.mean(serie_de_iris_col_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a47f49",
   "metadata": {},
   "source": [
    "Debido a las limitaciones de las *Series (como lo vimos previamente)* tendremos que dar paso a una nueva estructura de datos, y es aquí en donde los *Dataframes* entran en juego. Pero, ¿qué tal si primero describimos las columnas que vienen de nuestro dataset?\n",
    "\n",
    "De acuerdo con la descripcion encontrada en la página sabemos que tiene la siguiente estructura:\n",
    "\n",
    "| No. |      Columna         |  Tipo de dato | Posibles Valores                                |\n",
    "|-----|:--------------------:|--------------:|:------------------------------------------------|\n",
    "| 1   |  longitud del sepalo | float/cm      | Positivos                                       |\n",
    "| 2   |    ancho del sepalo  |   float/cm    | Positivos                                       |\n",
    "| 3   |  longitud del petalo |    float/cm   | Positivos                                       |\n",
    "| 4   |   ancho del petalo   |    float/cm   | Positivos                                       |\n",
    "| 5   |    clase             | string/texto  | Iris Setosa, Iris Versicolour,  Iris Virginica  |\n",
    "\n",
    "Es momento de que modifiquemos la *Serie*, y la convirtamos en un *Dataframe* y usemos a nuestro favor todo su potencial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57870dbb",
   "metadata": {},
   "source": [
    "##  Introducción a los DataFrames\n",
    "\n",
    "Un *DataFrame* es un arreglo de $n$ dimensiones de datos estructurados que puede almacenar datos de diferentes tipos. Si, es como una hoja de cálculo o una tabla de una base de datos.\n",
    "\n",
    "Los DataFrame son más comunes que las Series *(Aparecen por todos lados en la computación científica, en el análisis y visualización de datos y entre otros)*  y es por esta razón que serán objeto de estudio en la práctica.\n",
    "\n",
    "Por lo general se puede crear un `DataFrame` desde diferentes fuentes de datos, pero en esta ocasión seguiremos usando el dataset de los [`iris`](./data/iris.data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed6374",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.360647Z",
     "start_time": "2023-04-11T16:50:31.125234Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# URL para el archivo iris.data\n",
    "url = \"https://raw.githubusercontent.com/ramirezlab/CHEMO/main/2_PART_TWO/data/iris.data\"\n",
    "\n",
    "# Obtener los datos de la URL\n",
    "response = requests.get(url)\n",
    "iris_data = response.text\n",
    "\n",
    "# Convertir los datps en un DataFrame\n",
    "column_names = [\"long_sepalo\", \"ancho_sepalo\", \"long_petalo\", \"ancho_petalo\", \"clase\"]\n",
    "df_iris = pd.read_csv(StringIO(iris_data), names=column_names)\n",
    "\n",
    "# Imprimir los primeros 5 elementos del DataFrame\n",
    "print(df_iris.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01532f75",
   "metadata": {},
   "source": [
    "*Nota: de ahora en adelante siempre que queramos importar el contenido de un dataset local usaremos el método `read_csv` de la librería de Pandas.*\n",
    "\n",
    "Como vimos fue muy fácil construir el `DataFrame`, ahora, ¿qué tal si lo manipulamos?, podríamos contestar preguntas del tipo: ¿cuántas clases de iris tenemos?, ¿cuál es el tamaño promedio de la longitud del pétalo?, ¿para todas las clases o para una en particular? Veamos cómo se hace:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d741e",
   "metadata": {},
   "source": [
    "Si queremos trabajar con la primera columna, podemos hacerlo fácimente de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52e749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.360647Z",
     "start_time": "2023-04-11T16:50:31.140206Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_iris['long_sepalo'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07f8fc1",
   "metadata": {},
   "source": [
    "Los elementos de la columna se almacenan como una `Serie`, con la que se puede operar fácilmente, por ejemplo encontrar el promedio de la longitud del sépalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af42aa48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.360647Z",
     "start_time": "2023-04-11T16:50:31.156151Z"
    }
   },
   "outputs": [],
   "source": [
    "### Ejemplo 1: Promedio de Longitud del Sépalo sin importar la clase\n",
    "mean_long_sepalo = np.mean(df_iris['long_sepalo'])\n",
    "print('Tamaño promedio del pétalo de las iris:')\n",
    "print(mean_long_sepalo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a924b72a",
   "metadata": {},
   "source": [
    "Eso fue sencillo, hallar la media de $150$ filas y con ello, darle un poquito más de significado al dataset.\n",
    "\n",
    "Los *Dataframe* tienen muchos métodos que permiten operar, manipular, agrupar, filtrar los datos, entre otros. Veamos algunos de los más importantes:\n",
    "\n",
    "* **groupby**: sirve para agrupar las filas en torno al valor de alguna de sus columnas\n",
    "* **assign**: sirve para agregar nuevas columnas a partir de los valores de otras\n",
    "* **query**: sirve para filtrar el dataset a partir de alguna condición *(Como por ejemplo el valor de una columna)*\n",
    "* **filter**: filtra un Dataframe por columnas o filas de acuerdo con sus etiquetas en los índices. *(En buena medida, como el método `query` pero el filtro se basa en los índices)\n",
    "* **value_counts()**: sirve para contar cuantos valores en una columna\n",
    "\n",
    "¿Y ahora qué tal si calculamos la cantidad de clases de iris que tenemos? Veamos cómo se hace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb0801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.360647Z",
     "start_time": "2023-04-11T16:50:31.172109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ejemplo 2: se hace uso del método groupby para agrupar el dataframe por la columna clase\n",
    "print('El número de clases en el dataset es: ') \n",
    "len(df_iris.groupby('clase'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547bbd08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.360647Z",
     "start_time": "2023-04-11T16:50:31.188081Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# cuántos datos hay de cada clase\n",
    "df_iris['clase'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a619f7b",
   "metadata": {},
   "source": [
    "Ahora vamos a darle paso a las respuestas de las preguntas faltantes, veamos cúál es la media de la longitud del pétalo para la clase de *Iris-setosa* por medio del método **query**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029c74f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.360647Z",
     "start_time": "2023-04-11T16:50:31.203553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ejemplo 2: Promedio de la Longitud del Pétalo para la clase Iris-setosa\n",
    "df_iris_setosa = df_iris.query(\"clase == 'Iris-setosa'\")\n",
    "mean_long_petalo = np.mean(df_iris_setosa['long_petalo'])\n",
    "print('Tamaño promedio del pétalo de la clase Iris-setosa:')\n",
    "print(mean_long_petalo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a29b84",
   "metadata": {},
   "source": [
    "Y ahora haremos uso del **Method Chain** para calcular un valor computado en una nueva columna usando el método `assign`, ¿que significa eso del Method Chain?, difícil traducirlo al español pero digamos que es la posibilidad de invocar diferentes métodos sobre un mismo objeto en una misma línea de código, separando cada uno por un punto `.`\n",
    " Un ejemplo es mejor que mil palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830a52c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.361645Z",
     "start_time": "2023-04-11T16:50:31.225492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ejemplo 3: Proporción computada del tamaño del pétalo para la clase Iris-virginica\n",
    "# Primero se filtran los elementos de clase Iris-virginica, luego se crea una nueva columna donde se divide el ancho y la longitud del pétalo, finalmente se muestran solo los primeros cinco elementos.\n",
    "df_iris.query('clase == \"Iris-virginica\"').assign(proporcion_petalo=lambda i: i['ancho_petalo'] / i['long_petalo']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2bcf",
   "metadata": {},
   "source": [
    "Y con esto logramos contestar las preguntas propuestas previamente. De forma que es fácil manipular un *DataFrame* al tiempo que jugamos con sus datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa7b68",
   "metadata": {},
   "source": [
    "## Más sobre los DataFrames\n",
    "\n",
    "\n",
    "Para continuar con la práctica, sería bueno dar un pequeño repaso sobre las ideas de manipulación más básicas y estándar de los *DataFrames*. Lo haremos al mismo tiempo que encontraremos la *desviación estándar sobre la longitud de los pétalos* de la clase *Iris-versicolor*.\n",
    "\n",
    "Este proceso demostrativo, de manipulación básica será paso a paso al mismo tiempo que nuevas columnas son agregadas, y para mayor comodidad trabajaremos con una porción del dataset original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313446cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.361645Z",
     "start_time": "2023-04-11T16:50:31.236476Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ejemplo 4: Calcular la desviación estándar del largo del pétalo para la clase Iris Versicolor\n",
    "df_iris_versicolor = df_iris.query('clase == \"Iris-versicolor\"').copy()\n",
    "\n",
    "# Se calcula la media del largo del pétalo\n",
    "media_long_petalo = np.mean(df_iris_versicolor['long_petalo'])\n",
    "\n",
    "# Se crea una columna con la resta de la media de cada largo del pétalo\n",
    "df_iris_versicolor['long_petalo_minus_media'] = df_iris_versicolor['long_petalo'] - media_long_petalo\n",
    "\n",
    "# Se crea una columna con la diferencia anterior al cuadrado\n",
    "df_iris_versicolor['long_petalo_minus_media_square'] = (df_iris_versicolor['long_petalo'] - media_long_petalo)**2\n",
    "\n",
    "# Se calcula la media elevada al cuadrado\n",
    "media_long_petalo_error = np.mean(df_iris_versicolor['long_petalo_minus_media_square'])\n",
    "\n",
    "# Se calcula desviación estándar\n",
    "print(f'DevSt = {np.square(media_long_petalo_error)}')\n",
    "\n",
    "# Se imprime el dataset\n",
    "df_iris_versicolor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6df894",
   "metadata": {},
   "source": [
    "Como observamos, el cálculo fue bastante abrumador y es por esto por lo que los métodos previamente expuestos permiten de alguna forma que en tan pocas líneas de código se logre mucho.\n",
    "Por ejemplo, podemos hacer lo mismo mucho más eficiente con el método `np.std()`. Tomando como parámetro la columna 'long_petalo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27936d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:31.361645Z",
     "start_time": "2023-04-11T16:50:31.267394Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "devstd_long_petalo = np.std(df_iris_versicolor['long_petalo'])\n",
    "print(f'DevSt = {devstd_long_petalo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa16fbb-1a4e-48a9-ac27-b627b2c602da",
   "metadata": {},
   "source": [
    "# Práctica 1: Adquirir datos de ChEMBL\n",
    "\n",
    "## Conceptos a trabajar\n",
    "**[Uniprot](https://www.uniprot.org/):** Es una base de datos que busca proporcionar a la comunidad científica un recurso integral, de alta calidad y de libre acceso de secuencias de proteínas e información funcional<sup> **1** </sup>.\n",
    "\n",
    "**[ChEMBL](https://www.ebi.ac.uk/chembl/):** Es una base de datos que contiene moléculas bioactivas, reune datos químicos, de bioactividad y genómicos<sup> **2** </sup>.\n",
    "\n",
    "**Mitad de la concentración inhibitoria máxima (IC50):** Expresa la cantidad de fármaco necesaria para inhibir un proceso biológico a la mitad del valor no inhibido, es la medida más utilizada de la eficacia o potencia de un fármaco<sup> **3** </sup>.\n",
    "\n",
    "**pIC50:** Es el logaritmo negativo en base diez del IC50, cuando las unidades de son **molares (M)**. Se usa para facilitar la comparación entre distintos IC50. También, es importante saber que a mayor pIC50 el fármaco tiene una mayor eficacia o mayor potencial<sup> **3** </sup>.\n",
    "\n",
    "**Mitad de la concentración máxima efectiva (EC50):** Es la concentración efectiva para producir el 50% de la respuesta máxima, se usa para comparar las potencias de los fármacos. También, es importante saber que a menor valor del EC50 más potente será el fármaco. A esta medida también se le calcula el logaritmo negativo en base diez **(pEC50)** para facilitar su comprensión<sup> **4** </sup>.\n",
    "\n",
    "**Constante de inhibición (Ki):** Es la concentración requerida para producir la mitad de la inhibición máxima, es útil para describir la afinidad de unión de una molécula a un receptor.\n",
    "\n",
    "**SMILES (Simplified Molecular-Input Line-Entry System):** Es una notación de línea para describir estructuras químicas utilizando cadenas ASCII cortas<sup> **5** </sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7663773-6f54-47bf-9c9a-1eff4eb5b10a",
   "metadata": {},
   "source": [
    "## Planteamiento del problema\n",
    "Para una investigación queremos identificar los compuestos que actúan con un target específico, la proteína Glucógeno sintasa quinasa-3 beta, actúa como un regulador negativo en el control hormonal de la homeostasis de la glucosa, señalización Wnt y regulación de factores de transcripción y microtúbulos.\n",
    "\n",
    "En esta práctica vamos a explorar y conocer los compuestos bioactivos de la proteína, sus estructuras y algunas características fisicoquímicas.\n",
    "\n",
    "Para lo cual, usaremos la información que proporciona la base de datos **ChEMBL**, que nos permite filtrar y descargar los datos de bioactividad conocidos de los compuestos que interactúan con nuestro target de interés. Posteriormente, trabajaremos los datos en un ` DataFrame `, que nos permitirá organizarlos, visualizarlos y manipularlos fácilmente.\n",
    "\n",
    "Lo primero que debemos hacer es conectarnos a **ChEMBL**, empleando la biblioteca **webresource client**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84dc1df-030e-4a1d-a809-4ac8edd672fd",
   "metadata": {},
   "source": [
    "## Conectarse a la base de datos ChEMBL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2612c-a497-4cb8-bd51-fdcefcb13e42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:33.179240Z",
     "start_time": "2023-04-11T16:50:31.283340Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install chembl_webresource_client\n",
    "!pip install rdkit\n",
    "\n",
    "from chembl_webresource_client.new_client import new_client #Se importa la biblioteca webresource client que permite conectase a ChEMBL\n",
    "import pandas as pd\n",
    "import math\n",
    "from rdkit.Chem import PandasTools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8cdc0-6939-4c4c-a183-374eacace60b",
   "metadata": {},
   "source": [
    "Se deben crear para el acceso a la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568fddfc-ef9a-4189-911d-8f0e3d00c5ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:33.192402Z",
     "start_time": "2023-04-11T16:50:33.178242Z"
    }
   },
   "outputs": [],
   "source": [
    "targets = new_client.target\n",
    "compounds = new_client.molecule\n",
    "bioactivities = new_client.activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d7e2d7-f5a2-4473-83bd-2daff23ef7d3",
   "metadata": {},
   "source": [
    "## Datos del target \n",
    "Luego, debemos buscar el ID del target de interés en la base de datos Uniprot, que en este caso es Glucógeno sintasa quinasa-3 beta, ID: [P49841](https://www.uniprot.org/uniprot/P49841)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf0217-bde5-40ea-be59-73092c07b5c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:33.267767Z",
     "start_time": "2023-04-11T16:50:33.194384Z"
    }
   },
   "outputs": [],
   "source": [
    "uniprot_id = 'P49841'\n",
    "# Se toma sola alguna información de  ChEMBL que sea de interés\n",
    "target_P49841 = targets.get(target_components__accession=uniprot_id) \\\n",
    "                     .only('target_chembl_id', 'organism', 'pref_name', 'target_type')\n",
    "pd.DataFrame.from_records(target_P49841)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b05cd6-df7a-47fc-b396-f181a6118b97",
   "metadata": {},
   "source": [
    "Vamos a seleccionar el target de interés `CHEMBL262` y guardar el ChEMBL-ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab282de-f599-4496-b5b3-78158b787d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:33.267767Z",
     "start_time": "2023-04-11T16:50:33.224894Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seleccionar el target de interes\n",
    "target = target_P49841[0]\n",
    "print(f'El target de interés es: {str(target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522cf8d-d0eb-478e-90c7-86fd833bc412",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:33.267767Z",
     "start_time": "2023-04-11T16:50:33.240839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardar el ChEMBL-ID\n",
    "chembl_id = target['target_chembl_id']\n",
    "print(f'El ChEMBL-ID de interés es: {chembl_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d287d52d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datos de bioactividad\n",
    "\n",
    "Ahora consultamos los datos de bioactividad que son de interés. Los pasos a seguir son:\n",
    "1. Descargar y filtrar bioactividades para el target\n",
    "    Los datos de bioactividad se van a filtrar de la siguiente manera:\n",
    "        * Tipo de bioactividad: IC50, EC50, Ki\n",
    "        * Relación: \"=\"\n",
    "2. Convertir los datos descargados en un data frame:\n",
    "    Las columnas de interés son: `molecule_chembl_id`, `type`, `relation`, `pchembl_value`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab8630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.349617Z",
     "start_time": "2023-04-11T16:50:33.257792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Primero, descargamos toda la base de datos\n",
    "bioact_temp = bioactivities.filter(target_chembl_id = chembl_id)\\\n",
    "                      .filter(relation = '=') \\\n",
    "                      .only('molecule_chembl_id', 'type', 'relation', 'standar_value', 'standar_units', 'pchembl_value', )\n",
    "df_bioact_temp = pd.DataFrame(bioact_temp)\n",
    "# se re organizan las columnas\n",
    "df_bioact_temp = df_bioact_temp[['molecule_chembl_id', 'type', 'relation', 'value', 'units', 'pchembl_value']]\n",
    "df_bioact_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bad24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.420960Z",
     "start_time": "2023-04-11T16:50:34.350614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Luego, filtramos por el tipo de actividad deseada\n",
    "df_bioact = df_bioact_temp[(df_bioact_temp['type'] == 'IC50') |\n",
    "                             (df_bioact_temp['type'] == 'EC50')|\n",
    "                             (df_bioact_temp['type'] == 'Ki')]\n",
    "print(f'Total de datos cargados: {len(df_bioact)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ad0fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.487781Z",
     "start_time": "2023-04-11T16:50:34.364575Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# primeros compuestos del dataframe\n",
    "df_bioact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef393e",
   "metadata": {},
   "source": [
    "Recordemos que el método `.head()` muestra los cinco primeros elementos del `dataframe`, sin embargo, podemos ver rápidamente qué elementos hay en las columnas *relation* y *type*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e950a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.487781Z",
     "start_time": "2023-04-11T16:50:34.399501Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_bioact['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9af663a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.506260Z",
     "start_time": "2023-04-11T16:50:34.412982Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_bioact['type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7f216e",
   "metadata": {},
   "source": [
    "Ya que la columna *relation* tiene solo un tipo (esto se debe al filtro inicial de la base de datos), podemos quitarla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b947b7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.510249Z",
     "start_time": "2023-04-11T16:50:34.435920Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_bioact.pop('relation')\n",
    "df_bioact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58875462-fe53-4001-8cb3-b8513708d37a",
   "metadata": {},
   "source": [
    "### Limpiar los datos\n",
    "Es posible que algunos compuestos tengan valores faltantes y también duplicados, ya que el mismo compuesto puede haber sido probado más de una vez (nosotros nos quedaremos solo con el que primero haya sido probado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d74226-b9dc-4143-8048-872b15ddbc0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.639437Z",
     "start_time": "2023-04-11T16:50:34.442903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Primero verificamos cuantos compuestos tenemos en total\n",
    "ori_len = len(df_bioact)\n",
    "print(f'Total de compuestos originales es: {ori_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e013877-f792-4177-8b3f-4740f67a8176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.640447Z",
     "start_time": "2023-04-11T16:50:34.458880Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se eliminan los compuestos que no tienen pChEMBL_value\n",
    "df_bioact = df_bioact.dropna(axis=0, how = 'any')\n",
    "new_len = len(df_bioact)\n",
    "print(f'Total de compuestos después de eliminar aquellos con datos faltantes: {new_len}')\n",
    "# Se le resta al número total de compuestos el número total de compuestos al eliminar los que no tienen pChEMBL_value\n",
    "print(f'Total compuestos eliminados {ori_len - new_len}')\n",
    "ori_len = new_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fdcc5-ac95-4ddf-be47-2ef940619532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.640447Z",
     "start_time": "2023-04-11T16:50:34.475827Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se eliminan los compuestos duplicados y nos quedamos con el primer compuesto probado\n",
    "df_bioact = df_bioact.drop_duplicates('molecule_chembl_id', keep = 'first')\n",
    "new_len = len(df_bioact)\n",
    "print(f'Total de compuestos sin duplicados : {new_len}')\n",
    "# Se le resta al número total de compuestos al eliminar los que no tienen pChEMBL_value el número total de compuestos sin duplicados\n",
    "print(f'Total compuestos eliminados {ori_len - new_len}')\n",
    "ori_len = new_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee296c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.640447Z",
     "start_time": "2023-04-11T16:50:34.490776Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_bioact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a26f580-dd5b-4c51-a8c1-889b9621c64e",
   "metadata": {},
   "source": [
    "Ahora que hemos eliminado algunas filas restableceremos el índice para que este sea continuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bbf5d-c428-4bc5-bd97-e04d669295bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.662391Z",
     "start_time": "2023-04-11T16:50:34.506260Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bioact.reset_index(drop=True, inplace=True)\n",
    "df_bioact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf55ab4-486f-485a-9414-b1c4e38682be",
   "metadata": {},
   "source": [
    "### Organizar los datos\n",
    "Vamos a organizar el DataFrame de mayor a menor pchembl_value. Notemos que los valores de la columna no son numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee74b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.663373Z",
     "start_time": "2023-04-11T16:50:34.522217Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(df_bioact['pchembl_value'][0],type(df_bioact['pchembl_value'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e0d7c",
   "metadata": {},
   "source": [
    "Por tanto, primero debemos convertirlos en tipo `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98268ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.721811Z",
     "start_time": "2023-04-11T16:50:34.538174Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_bioact['pchembl_value'] = df_bioact['pchembl_value'].astype(float)\n",
    "print(df_bioact['pchembl_value'][0],type(df_bioact['pchembl_value'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022d9ed",
   "metadata": {},
   "source": [
    "Ahora procedemos a organizar el DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648690df-a26b-486b-83fd-d812139fa3df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.725789Z",
     "start_time": "2023-04-11T16:50:34.552137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Organizamos de mayor a menor pchembl_value\n",
    "df_bioact.sort_values(by=\"pchembl_value\", ascending=False, inplace=True)\n",
    "# Restablecemos el índice\n",
    "df_bioact.reset_index(drop=True, inplace=True)\n",
    "# Imprimimos los primeros datos del Dataframe\n",
    "df_bioact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626601c2-45ff-4868-90f6-398cfb500bcd",
   "metadata": {},
   "source": [
    "### Guardar y cargar los datos\n",
    "Para continuar usando el Data Frame en la práctica sin necesidad de siempre estarnos conectando a ChEMBL, vamos a guardar el Data Frame obtenido como un archivo separado por comas (data/compuestos_uniprot_id.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93433e81-f986-4cab-86ce-6ce498637102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.725789Z",
     "start_time": "2023-04-11T16:50:34.568094Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./data\n",
    "df_bioact.to_csv(f\"./data/compounds_{uniprot_id}.csv\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce212f",
   "metadata": {},
   "source": [
    "En adelante, si queremos utilizar el Dataframe, podemos cargar el archivo guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e7e7e-1728-421c-b894-1bbf93ad78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/ramirezlab/CHEMO/main/2_PART_TWO/data/compounds_P49841.csv'\n",
    "df_bioact = pd.read_csv(url,parse_dates=[0])\n",
    "df_bioact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f74443-157b-4a05-8619-846f9b0df968",
   "metadata": {},
   "source": [
    "## Datos de los compuestos\n",
    "\n",
    "A continuación vamos a obtener los datos de las moléculas que estan almacenados dentro de cada molecule_chembl_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fad78ac-569e-40e6-a4ac-8076e5696f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librería necesaria para comunicarse con CHEMBL\n",
    "from chembl_webresource_client.new_client import new_client\n",
    "# libreria para trabajar con base de datos (Dataframes)\n",
    "import pandas as pd\n",
    "\n",
    "# Declaración de variables para instanciar el cliente de CHEMBL y acceder a la base de datos de las moléculas\n",
    "compounds = new_client.molecule\n",
    "\n",
    "# Cargamos el archivo antes guardado\n",
    "uniprot_id = 'P49841'\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/ramirezlab/CHEMO/main/2_PART_TWO/data/compounds_P49841.csv'\n",
    "df_bioact = pd.read_csv(url,parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96968a6-8b33-4a9b-8072-5c7db156fb88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:34.726787Z",
     "start_time": "2023-04-11T16:50:34.615517Z"
    }
   },
   "outputs": [],
   "source": [
    "# Primero tenemos que obtener la lista de los compuestos que definimos como bioactivos\n",
    "lista_comp_id = list(df_bioact['molecule_chembl_id'])\n",
    "# Obtener la estructura de cada compuesto\n",
    "lista_compuestos = compounds.filter(molecule_chembl_id__in = lista_comp_id) \\\n",
    "                            .only('molecule_chembl_id','molecule_structures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d436e5-8b30-4646-8c6b-d213d4e1cb53",
   "metadata": {},
   "source": [
    "Veamos la estructura de la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749b971-52d6-4010-aa49-595e71ed541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_compuestos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7061d81-a918-4fa3-9e85-acf4d0882a0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:35.206201Z",
     "start_time": "2023-04-11T16:50:34.630462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Debemos convertir la lista obtenida en un dataframe. Esto puede tardar unos minutos\n",
    "df_comp = pd.DataFrame(lista_compuestos)\n",
    "# Eliminamos duplicados\n",
    "df_comp = df_comp.drop_duplicates('molecule_chembl_id', keep = 'first')\n",
    "print(f'Total de compuestos es: {str(len(df_comp))}')\n",
    "df_comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ba27f-1564-40ff-aaf2-873ddce01521",
   "metadata": {},
   "source": [
    "Los compuestos tienen distintos tipos de representaciones como el SMILES, el InChI y el InChI Key. Nos interesa únicamente quedarnos con el SMILES, ya que describe la estructura química."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314eef2a-838b-459e-af78-3b3799d5db3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:35.459661Z",
     "start_time": "2023-04-11T16:50:35.113933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vamos a utilizar un ciclo for para iterar por cada renglón (df_comp.iterrows())\n",
    "for i, cmpd in df_comp.iterrows():\n",
    "    if df_comp.loc[i]['molecule_structures'] is not None:\n",
    "        df_comp.loc[i]['molecule_structures'] = cmpd['molecule_structures']['canonical_smiles']\n",
    "print(f'Total de compuestos: {len(df_comp)}')\n",
    "df_comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862083ee",
   "metadata": {},
   "source": [
    "### Limpiar las sales de los smiles\n",
    "Si se revisa con detalle la representación de *smiles* de cada molécula, podemos ver que algunas tienen *sales* que se deben limpiar.\n",
    "Primero filtremos las moleculas que tienen sales, usualmente se puede ver en los smiles porque tienen un punto en la cadena de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13bb8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:35.466654Z",
     "start_time": "2023-04-11T16:50:35.429740Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_comp[df_comp.molecule_structures.str.contains(\"\\.\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a57c07",
   "metadata": {},
   "source": [
    "Es decir, de los 2658 compuestos iniciales, 67 tienen sales que deben ser limpiadas. Podemos utilizar un módulo de `rdkit` para limpiar sales llamado `rdkit.Chem.SaltRemover`.\n",
    "Supongamos que queremos eliminar la sal del smile \"CN1CCN(CCO/N=C2C(=C3/C(=O)Nc4cc(Br)ccc43)/Nc3ccccc3/2)CC1.Cl\", se puede hacer los siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a68348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:35.466654Z",
     "start_time": "2023-04-11T16:50:35.447691Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# librerías\n",
    "from rdkit.Chem.SaltRemover import SaltRemover\n",
    "from rdkit.Chem import MolFromSmiles, MolToSmiles\n",
    "\n",
    "# Se carga el módulo para remover las sales\n",
    "remover = SaltRemover()\n",
    "# se convierte el smile a un objeto mol\n",
    "mol = MolFromSmiles('Br.CCCCCc1n/c(=N\\Cc2cccnc2)sn1-c1ccccc1')\n",
    "# se remueve las sales (res=molécula, deleted=fragmento eliminado)\n",
    "res, deleted = remover.StripMolWithDeleted(mol)\n",
    "# se convierte el objeto mol a smiles nuevamente y se eliminan espacios en blanco\n",
    "MolToSmiles(res).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add065c8",
   "metadata": {},
   "source": [
    "Ahora vamos a crear una función que haga este proceso para pasarla por el dataframe `df_comp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1bd4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:35.612315Z",
     "start_time": "2023-04-11T16:50:35.462653Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def remover_sales(smile):\n",
    "    remover = SaltRemover()\n",
    "    mol = MolFromSmiles(smile)\n",
    "    res, deleted = remover.StripMolWithDeleted(mol)\n",
    "    return MolToSmiles(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f50571",
   "metadata": {},
   "source": [
    "Aplicamos la función a la columna de los smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4510c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:40.034378Z",
     "start_time": "2023-04-11T16:50:35.477613Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_comp['molecule_structures'] = df_comp['molecule_structures'].apply(remover_sales)\n",
    "# Eliminar los espacios en blanco en los bordes de cada cadena en la columna \"molecule_structures\"\n",
    "df_comp[\"molecule_structures\"] = df_comp[\"molecule_structures\"].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff19ae",
   "metadata": {},
   "source": [
    "Volvemos a buscar smiles que tengan sales para comprobar que la limpieza fue exitosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd09f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:40.050925Z",
     "start_time": "2023-04-11T16:50:40.036391Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_comp[df_comp.molecule_structures.str.contains(\"\\.\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f3024",
   "metadata": {},
   "source": [
    "Ya limpiamos las sales de las moléculas, ahora debemos eliminar las moléculas con datos vacíos. Por ejemplo al limpiar la molécula \"[Cl-].[Li+]\" se eliminan las dos sales y la salida queda vacía `('')`. Para eliminar estos campos podemos utilizar `dropna` y filtrar por los que no son vacíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66037601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:40.128343Z",
     "start_time": "2023-04-11T16:50:40.051923Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_comp.dropna(subset=[\"molecule_structures\"], inplace=True)\n",
    "df_comp = df_comp[df_comp['molecule_structures'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63efe03",
   "metadata": {},
   "source": [
    "Y ya tenemos el conjunto de moléculas limpias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16416518-adc0-461c-8ba8-1cd0d8c8f03d",
   "metadata": {},
   "source": [
    "## Combinar los Dataframe\n",
    "\n",
    "Ahora tenemos dos dataframes que vamos a combinar para tener todos los datos en uno solo dataframe y poder guardarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aeec75-3767-4444-a6c7-8875303f87a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:40.190178Z",
     "start_time": "2023-04-11T16:50:40.067991Z"
    }
   },
   "outputs": [],
   "source": [
    "# En el Dataframe de bioactividad se filtran solamente dos columnas\n",
    "df_output = pd.merge(df_bioact[['molecule_chembl_id','pchembl_value']], df_comp, on='molecule_chembl_id')\n",
    "print(f'Total de compuestos es: {str(len(df_output))}')\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153402ff-b090-48f6-9a92-aff104c892e4",
   "metadata": {},
   "source": [
    "Se pueden renombrar las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaff736-a9ee-4547-be51-d77260de6f9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:40.190178Z",
     "start_time": "2023-04-11T16:50:40.083949Z"
    }
   },
   "outputs": [],
   "source": [
    "df_output = df_output.rename(columns= {'molecule_structures':'smiles'})\n",
    "print(f'Total de compuestos es: {str(len(df_output))}')\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba828e0-2ab3-4a0d-a638-35f81d237f7e",
   "metadata": {},
   "source": [
    "Para poder emplear la siguiente función de rdkit es necesario que todos los compuestos tengan SMILES, por esto eliminamos los compuestos sin SMILES en el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680a0e6-1220-4078-a235-40c2fc86173d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:40.191176Z",
     "start_time": "2023-04-11T16:50:40.099906Z"
    }
   },
   "outputs": [],
   "source": [
    "df_output = df_output[~df_output['smiles'].isnull()]\n",
    "print(f'Total de compuestos es: {str(len(df_output))}')\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ab5d4-0762-4983-ad1b-bff5e5d82357",
   "metadata": {},
   "source": [
    "## Dibujar la molécula\n",
    "\n",
    "Vamos a añadir una nueva columna al dataframe con la función `.AddMoleculeColumnToFrame` la cual convierte las moléculas contenidas en \"smilesCol\" en moléculas RDKit y las agrega al dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf4de68-a012-464c-93ee-4f316a4d950d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:40.751761Z",
     "start_time": "2023-04-11T16:50:40.114868Z"
    }
   },
   "outputs": [],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(df_output, smilesCol='smiles')\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f573681",
   "metadata": {},
   "source": [
    "Ahora podemos llamar a cualquier compuesto para ver su representación en 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65947622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:40.782678Z",
     "start_time": "2023-04-11T16:50:40.730817Z"
    }
   },
   "outputs": [],
   "source": [
    "df_output.ROMol.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d27814b-50c3-476e-8eb4-2784d28a7cd1",
   "metadata": {},
   "source": [
    "## Guardar el dataframe obtenido\n",
    "\n",
    "Se va a guardar el dataframe como un archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1887019d-902a-4e22-b721-7239dd9533a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T16:50:40.876996Z",
     "start_time": "2023-04-11T16:50:40.739793Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./data\n",
    "df_output.to_csv(f\"data/compounds_{uniprot_id}_full.csv\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9d893-0c03-402a-89d8-f2cc46c18ede",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "En esta práctica se empleó la base de datos ChEMBL para obtener datos de compuestos bioactivos frente a nuestro target de interés. Estos datos extraidos en forma de diccionarios y listas se convirtieron en un DataFrame el cual permite visualizar fácilmente la información obtenida. Además, se obtuvieron datos de los compuestos bioactivos, combinaron DataFrames, se renombraron columnas y se utilizó una herramienta de panda para añadir una nueva columna al DataFrame construido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f4c114",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "1. Coudert, E., Gehant, S., De Castro, E., Pozzato, M., Baratin, D., Neto, T., Sigrist, C. J. A., Redaschi, N., Bridge, A., The UniProt Consortium, Bridge, A. J., Aimo, L., Argoud-Puy, G., Auchincloss, A. H., Axelsen, K. B., Bansal, P., Baratin, D., Neto, T. M. B., Blatter, M.-C., … Wang, Y. (2023). Annotation of biologically relevant ligands in UniProtKB using ChEBI. Bioinformatics, 39(1), btac793. https://doi.org/10.1093/bioinformatics/btac793\n",
    "2. Mendez, D., Gaulton, A., Bento, A. P., Chambers, J., De Veij, M., Félix, E., Magariños, M. P., Mosquera, J. F., Mutowo, P., Nowotka, M., Gordillo-Marañón, M., Hunter, F., Junco, L., Mugumbate, G., Rodriguez-Lopez, M., Atkinson, F., Bosc, N., Radoux, C. J., Segura-Cabrera, A., … Leach, A. R. (2019). ChEMBL: Towards direct deposition of bioassay data. Nucleic Acids Research, 47(D1), D930-D940. https://doi.org/10.1093/nar/gky1075\n",
    "3. Aykul, S., & Martinez-Hackert, E. (2016). Determination of half-maximal inhibitory concentration using biosensor-based protein interaction analysis. Analytical Biochemistry, 508, 97-103. https://doi.org/10.1016/j.ab.2016.06.025\n",
    "4. Waller, D. G., & Sampson, A. P. (2018). Principles of pharmacology and mechanisms of drug action. En Medical Pharmacology and Therapeutics (pp. 3-31). Elsevier. https://doi.org/10.1016/B978-0-7020-7167-6.00001-4\n",
    "5. Daylight>cheminformatics. (2022). https://www.daylight.com/smiles/ \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
